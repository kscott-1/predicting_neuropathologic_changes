{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/tpjoe/tpjoe@stanford.edu/project_NACC/scripts/utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "from importlib import reload\n",
    "import copy\n",
    "\n",
    "import utils\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe, rename one column (to make it conform with description dataframe) and sort by patients ID\n",
    "# df = pd.read_csv('../data/phongpreecha03152021.csv', low_memory=False)\n",
    "df = pd.read_csv('df_samples.csv', low_memory=False)\n",
    "df = df.rename({'ADCNAME': 'NACCADC'}, axis=1)\n",
    "df = df.sort_values(['NACCID', 'NACCVNUM'])\n",
    "\n",
    "# Inspect columns with NAs\n",
    "colNA = df.isna().sum() > 0\n",
    "colNA = [colNA.keys().tolist()[i] for i in np.array(np.where(colNA.tolist()))[0, :]]\n",
    "colNA = pd.DataFrame(df.isna().sum()[colNA]).transpose()\n",
    "# colNA.iloc[0, :].value_counts().index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only UDS, this would eradicate the 8000NA peak\n",
    "df_UDS = df.loc[df.NACCMDSS != 2, :] # most features in NACCMDSS == 2 are just NP and only MMSE available, no lifestyle data\n",
    "# df_UDS = df_UDS.loc[:, (df_UDS.isna().sum() < 500)]\n",
    "\n",
    "# creating visit feature \n",
    "visit = df_UDS.groupby(['NACCID']).cumcount() + 1\n",
    "\n",
    "# read back those marked features\n",
    "marked_features = pd.read_csv('NA_less_than_20000_new_type_filled.csv')\n",
    "df_UDS = df_UDS.loc[:, df_UDS.columns.isin(marked_features.var_name.values)]\n",
    "\n",
    "# split data to X and y\n",
    "# y_col_UDS = pd.DataFrame(df_UDS.columns)[0].apply(lambda i: True if (marked_features.loc[marked_features.var_name==i, 'type'].values[0]=='y') else False).tolist()\n",
    "x_col_UDS = pd.DataFrame(df_UDS.columns)[0].apply(lambda i: True if (marked_features.loc[marked_features.var_name==i, 'type'].values[0]=='x') else False).tolist()\n",
    "X_UDS = df_UDS.loc[:, ['NACCID', 'NACCVNUM'] + list(df_UDS.columns[x_col_UDS])]\n",
    "# y_UDS = df_UDS.loc[:, ['NACCID', 'NACCVNUM'] + list(df_UDS.columns[y_col_UDS])]\n",
    "\n",
    "# Let's select just those that have meaningful amount of data first\n",
    "# y_UDS = y_UDS.loc[:, y_UDS.applymap(lambda x: (x==88.8)|(x==-4)).sum() < 10000]\n",
    "X_UDS = X_UDS.loc[:, X_UDS.loc[df.NACCVNUM==1, :].applymap(lambda x: x==-4).sum() < 1000]\n",
    "# Xy_UDS = pd.concat([X_UDS, y_UDS], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83266/2846450979.py:52: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  X_UDS[id_features] = X_UDS.groupby('NACCID')[id_features].apply(lambda x: x.fillna(method='ffill'))\n"
     ]
    }
   ],
   "source": [
    "# start preprocessing\n",
    "guidelines = pd.read_csv('processing_guidelines_updated.csv')\n",
    "\n",
    "# start with those that will be dropped (D)\n",
    "drop_features = guidelines.loc[['D' in c for c in guidelines.cleared.tolist()], 'feature'].tolist()\n",
    "if any(i in X_UDS.columns for i in drop_features):\n",
    "    X_UDS = X_UDS.drop(drop_features, axis=1)\n",
    "\n",
    "# PRIMLANG\n",
    "X_UDS.loc[X_UDS.PRIMLANG.isin([3, 4, 6, 9]), 'PRIMLANG'] = 8 # get rid of some minor lagnaguses\n",
    "\n",
    "# those where -4 and 9 must be combined (c)\n",
    "combine_features = guidelines.loc[[c=='c' for c in guidelines.cleared.tolist()], 'feature'].tolist()\n",
    "combine_features = [i for i in combine_features if i != 'PRIMLANG']\n",
    "X_UDS[combine_features] = X_UDS[combine_features].stack().replace({-4:9}).unstack()\n",
    "\n",
    "# those that -4 needs to be replaced by copied value from the 1st visit\n",
    "dup_features = ['NPSYLAN']\n",
    "X_UDS.loc[:, dup_features] = X_UDS.loc[:, dup_features].replace(-4, np.nan) # no first visit = -4\n",
    "X_UDS.loc[:, dup_features] = X_UDS.loc[:, dup_features].fillna(method='ffill')\n",
    "\n",
    "# impute only (i; continuos)\n",
    "impCon_features = guidelines.loc[(guidelines.cleared=='i') & (guidelines['categ']=='n'), 'feature'].tolist()\n",
    "for i, col in enumerate(impCon_features):\n",
    "    X_UDS.loc[:, col] = X_UDS.loc[:, col].replace([-4, 99], np.nan)\n",
    "    X_UDS.loc[:, col] = X_UDS.loc[:, col].fillna(X_UDS.loc[:, col].mean())\n",
    "\n",
    "# impute only (i; categ)\n",
    "impCateg_features = guidelines.loc[(guidelines.cleared=='i') & (guidelines['categ']=='y'), 'feature'].tolist()\n",
    "for i, col in enumerate(impCateg_features):\n",
    "    X_UDS.loc[:, col] = X_UDS.loc[:, col].replace([9, 99], X_UDS.loc[:, col].value_counts().idxmax())\n",
    "\n",
    "# those needing imputation and duplicates (ic)\n",
    "ic_features = guidelines.loc[[c=='ic' for c in guidelines.cleared.tolist()], 'feature'].tolist()\n",
    "ic_features = [i for i in ic_features if i != 'DECAGE']\n",
    "for i, col in enumerate(ic_features):\n",
    "    X_UDS.loc[:, col] = X_UDS.loc[:, col].replace([-4, 9], np.nan)\n",
    "    X_UDS.loc[:, col] = X_UDS.loc[:, col].fillna(X_UDS.loc[:, col].mean())\n",
    "\n",
    "X_UDS[ic_features] = X_UDS[ic_features].stack().replace({8:0}).unstack()\n",
    "\n",
    "# special ic: DECAGE\n",
    "X_UDS.loc[:, 'DECAGE'] = X_UDS.loc[:, 'DECAGE'].replace([999], np.nan)\n",
    "X_UDS.loc[:, 'DECAGE'] = X_UDS.loc[:, 'DECAGE'].fillna(X_UDS.loc[:, 'DECAGE'].mean())\n",
    "X_UDS.loc[X_UDS.DECAGE!=888, 'DECAGE'] = 1/X_UDS.loc[X_UDS.DECAGE!=888, 'DECAGE']\n",
    "X_UDS.loc[X_UDS.DECAGE==888, 'DECAGE'] = 0\n",
    "\n",
    "# those needing imputation and duplicates (id)\n",
    "id_features = guidelines.loc[['id' == c for c in guidelines.cleared.tolist()], 'feature'].tolist()\n",
    "X_UDS.loc[:, id_features] = X_UDS.loc[:, id_features].replace(9, 0) # most are 0s in the first visit\n",
    "X_UDS.loc[:, id_features] = X_UDS.loc[:, id_features].replace(-4, np.nan)\n",
    "X_UDS[id_features] = X_UDS.groupby('NACCID')[id_features].apply(lambda x: x.fillna(method='ffill'))\n",
    "\n",
    "# those needing imputation and duplicates (icd non-categ)\n",
    "X_UDS.loc[(df_UDS.NACCVNUM==1) & ((X_UDS.SMOKYRS==88) | (X_UDS.SMOKYRS==99)), 'SMOKYRS'] = np.nan\n",
    "X_UDS['SMOKYRS'] = X_UDS['SMOKYRS'].fillna(X_UDS['SMOKYRS'].mean())\n",
    "year_inc = pd.concat([X_UDS[['NACCID', 'NACCAGE']].groupby(['NACCID']).diff(), X_UDS.NACCID], axis=1).groupby('NACCID').cumsum().fillna(0)\n",
    "smok_1stvisit = X_UDS.loc[df_UDS.NACCVNUM==1, 'SMOKYRS'].repeat(X_UDS.NACCID.value_counts())\n",
    "smok_1stvisit.index = year_inc.index\n",
    "year_smok = year_inc.NACCAGE + smok_1stvisit\n",
    "X_UDS.loc[X_UDS['SMOKYRS']==-4, 'SMOKYRS'] = year_smok.loc[X_UDS.SMOKYRS==-4]\n",
    "\n",
    "# icd, inverse age, and categ\n",
    "icd_noncateg = guidelines.loc[(guidelines.cleared == 'icd') & (guidelines.categ == 'n'), 'feature'][1:].values.tolist()\n",
    "year_inc = pd.concat([X_UDS[['NACCID', 'NACCAGE']].groupby(['NACCID']).diff(), X_UDS.NACCID], axis=1).groupby('NACCID').cumsum().fillna(0)\n",
    "for col in icd_noncateg:\n",
    "    X_UDS.loc[X_UDS[col] == -4, col] = np.nan\n",
    "    X_UDS.loc[:, col] = X_UDS.loc[:, col].fillna(method='ffill')\n",
    "    if col == 'QUITSMOK':\n",
    "        X_UDS.loc[X_UDS[col] == 888, col] = 0\n",
    "        X_UDS.loc[X_UDS[col] == 999, col] = X_UDS.loc[X_UDS[col] != 999, col].mean()\n",
    "    else:\n",
    "        X_UDS.loc[~X_UDS[col].isin([8888, 9999]), col] = 1/X_UDS.loc[~X_UDS[col].isin([8888, 9999]), col]\n",
    "        X_UDS.loc[X_UDS[col] == 8888, col] = 0\n",
    "        X_UDS.loc[X_UDS[col] == 9999, col] = X_UDS.loc[X_UDS[col] != 9999, col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83266/1697332255.py:138: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_UDS_caseII.loc[:, special_feat] = imputed_df.loc[:, special_feat]\n"
     ]
    }
   ],
   "source": [
    "# r features\n",
    "replace_dict = {'SPEECH': {'replacedBy': 'APRAXSP', 'nonzerokey':{1:2}},\n",
    "                'TRESTRHD': {'replacedBy': 'RESTTRL', 'nonzerokey':{1:2}},\n",
    "                'TRESTLHD': {'replacedBy': 'RESTTRR', 'nonzerokey':{1:2}},\n",
    "                'TRACTRHD': {'replacedBy': 'POSTINST', 'nonzerokey':{1:2}},\n",
    "                'TRACTLHD': {'replacedBy': 'POSTINST', 'nonzerokey':{1:2}},\n",
    "                'LEGRT': {'replacedBy': 'CVDMOTR', 'nonzerokey':{1:2}},\n",
    "                'LEGLF': {'replacedBy': 'CVDMOTL', 'nonzerokey':{1:2}},\n",
    "                'POSTURE': {'replacedBy': 'POSTINST', 'nonzerokey':{1:2}},\n",
    "                'POSSTAB': {'replacedBy': 'POSTINST', 'nonzerokey':{1:2}},\n",
    "                'BRADYKIN': {'replacedBy': 'BRADY', 'nonzerokey':{1:1}},\n",
    "                'NACCPPME': {'replacedBy': 'NACCPPAG', 'nonzerokey':{1:2, 2:4, 3:1, 4:4, 7:7, 8:8, -4:8}},\n",
    "                'VASC': {'replacedBy': 'CVD', 'nonzerokey':{1:1}},\n",
    "                'VASCIF': {'replacedBy': 'CVDIF', 'nonzerokey':{1:1, 2:2, 3:7, 7:7, 8:8, 3:7, -4:8}},\n",
    "                'STROKE': {'replacedBy': 'PREVSTK', 'nonzerokey':{1:1}},\n",
    "                'STROKIF': {'replacedBy': 'STROKDEC', 'nonzerokey':{1:2, 8:8}}         \n",
    "                }\n",
    "r_features = list(replace_dict.keys())\n",
    "mod_df = df.copy()\n",
    "if not all(X_UDS.index == mod_df.index): print('SHITTTTTTTTTTTT')\n",
    "\n",
    "for replaced_f in replace_dict.keys():\n",
    "    mod_df[replace_dict[replaced_f]['replacedBy']] = mod_df[replace_dict[replaced_f]['replacedBy']].apply(lambda x: 0 \\\n",
    "        if x not in replace_dict[replaced_f]['nonzerokey'].keys() else replace_dict[replaced_f]['nonzerokey'][x])\n",
    "    replaced_row = X_UDS.loc[X_UDS.loc[:, replaced_f]==-4, :].index    \n",
    "    X_UDS.loc[replaced_row, replaced_f] = mod_df.loc[replaced_row, replace_dict[replaced_f]['replacedBy']]\n",
    "\n",
    "\n",
    "# r2 features\n",
    "r2_features = ['FOCLSIGN', 'FACEXP', 'GAIT']\n",
    "\n",
    "replaced_f = 'FOCLSIGN'\n",
    "value_holder = df.loc[:, ['CVDSIGNS', 'SIVDFIND']].apply(lambda x: 2 if ((x.CVDSIGNS==1) & (x.SIVDFIND==1)) else 0, axis=1)\n",
    "replaced_row = X_UDS.loc[X_UDS.loc[:, replaced_f]==-4, :].index\n",
    "X_UDS.loc[replaced_row, replaced_f] = value_holder.loc[replaced_row]\n",
    "\n",
    "replaced_f = 'FACEXP'\n",
    "value_holder = df.loc[:, ['CVDMOTL', 'CVDMOTR']].apply(lambda x: 2 if ((x.CVDMOTL==1) | (x.CVDMOTR==1)) else 0, axis=1)\n",
    "replaced_row = X_UDS.loc[X_UDS.loc[:, replaced_f]==-4, :].index\n",
    "X_UDS.loc[replaced_row, replaced_f] = value_holder.loc[replaced_row]\n",
    "\n",
    "replaced_f = 'GAIT'\n",
    "value_holder = df.loc[:, ['PARKGAIT', 'GAITNPH', 'GAITPSP']].apply(lambda x: 2 if ((x.PARKGAIT==1) | (x.GAITNPH==1) | (x.GAITPSP==1)) else 0, axis=1)\n",
    "replaced_row = X_UDS.loc[X_UDS.loc[:, replaced_f]==-4, :].index\n",
    "X_UDS.loc[replaced_row, replaced_f] = value_holder.loc[replaced_row]\n",
    "\n",
    "\n",
    "# ir features\n",
    "replace_dict = {'CVHATT': {'replacedBy': 'MYOINF', 'nonzerokey':{1:1}},\n",
    "                'CVAFIB': {'replacedBy': 'AFIBRILL', 'nonzerokey':{1:1}},\n",
    "                'CVPACE': {'replacedBy': 'PACEMAKE', 'nonzerokey':{1:1}},\n",
    "                'CVCHF': {'replacedBy': 'CONGHRT', 'nonzerokey':{1:1}},\n",
    "                'CBSTROKE': {'replacedBy': 'PREVSTK', 'nonzerokey':{1:1}},\n",
    "                'NACCTBI': {'replacedBy': 'BRNINJ', 'nonzerokey':{1:1}},\n",
    "                'TRAUMCHR': {'replacedBy': 'BRNINJ', 'nonzerokey':{1:1}},\n",
    "                'NCOTHR': {'replacedBy': 'OTHCOG', 'nonzerokey':{1:1}},\n",
    "                'DIABETES': {'replacedBy': 'DIABET', 'nonzerokey':{1:1, 2:1, 3:1}},\n",
    "                'HYPERTEN': {'replacedBy': 'HYPERT', 'nonzerokey':{1:1}},\n",
    "                'B12DEF': {'replacedBy': 'VB12DEF', 'nonzerokey':{1:1}},\n",
    "                'THYROID': {'replacedBy': 'THYDIS', 'nonzerokey':{1:1}},\n",
    "                'INCONTU': {'replacedBy': 'BOWLINC', 'nonzerokey':{1:1}},\n",
    "                'INCONTF': {'replacedBy': 'NACCPPAG', 'nonzerokey':{1:1}},\n",
    "                'ALCOHOL': {'replacedBy': 'ALCABUSE', 'nonzerokey':{1:1}},\n",
    "                'ABUSOTHR': {'replacedBy': 'IMPSUB', 'nonzerokey':{1:1}},\n",
    "                'DEP2YRS': {'replacedBy': 'DEPD', 'nonzerokey':{1:1}},\n",
    "                'DEPOTHR': {'replacedBy': 'DEPD', 'nonzerokey':{1:1}}    \n",
    "                }\n",
    "ir_features = list(replace_dict.keys()) + ['CVANGIO', 'TRAUMBRF', 'TRAUMEXT']\n",
    "mod_df = df.copy()\n",
    "if not all(X_UDS.index == mod_df.index): print('SHITTTTTTTTTTTT')\n",
    "\n",
    "for replaced_f in replace_dict.keys():\n",
    "    mod_df[replace_dict[replaced_f]['replacedBy']] = mod_df[replace_dict[replaced_f]['replacedBy']].apply(lambda x: 0 \\\n",
    "        if x not in replace_dict[replaced_f]['nonzerokey'].keys() else replace_dict[replaced_f]['nonzerokey'][x])\n",
    "    replaced_row = X_UDS.loc[X_UDS.loc[:, replaced_f]==-4, :].index    \n",
    "    X_UDS.loc[replaced_row, replaced_f] = mod_df.loc[replaced_row, replace_dict[replaced_f]['replacedBy']]\n",
    "\n",
    "# special ir cases\n",
    "value_holder = df.loc[:, ['ANGIOCP', 'ANGIOPCI']].apply(lambda x: 1 if ((x.ANGIOCP==1) | (x.ANGIOPCI==1)) else 0, axis=1)\n",
    "replaced_row = X_UDS.loc[X_UDS.loc[:, 'CVANGIO']==-4, :].index\n",
    "X_UDS.loc[replaced_row, 'CVANGIO'] = value_holder.loc[replaced_row]\n",
    "X_UDS.loc[X_UDS.TRAUMBRF==-4, 'TRAUMBRF'] = df.loc[X_UDS.TRAUMBRF==-4, 'TBIBRIEF']\n",
    "X_UDS.loc[X_UDS.TRAUMBRF==-4, 'TRAUMBRF'] = df.loc[X_UDS.TRAUMBRF==-4, 'BRNINJ']\n",
    "X_UDS.loc[X_UDS.TRAUMEXT==-4, 'TRAUMEXT'] = df.loc[X_UDS.TRAUMEXT==-4, 'TBIBRIEF']\n",
    "X_UDS.loc[X_UDS.TRAUMEXT==-4, 'TRAUMEXT'] = df.loc[X_UDS.TRAUMEXT==-4, 'BRNINJ']\n",
    "\n",
    "# imputing 9 \n",
    "X_UDS.loc[:, ir_features] = X_UDS.loc[:, ir_features].replace({9:np.nan})\n",
    "X_UDS.loc[:, ir_features] = X_UDS.loc[:, ir_features].fillna(X_UDS.loc[:, ir_features].mode().iloc[0])\n",
    "\n",
    "\n",
    "# s2 cases\n",
    "s2_features = guidelines.loc[(guidelines.cleared == 's2'), 'feature'].values.tolist()\n",
    "# first where -4 and 9 must be combined (c) in the first visit\n",
    "X_UDS.loc[df.NACCVNUM==1, combine_features] = X_UDS.loc[df.NACCVNUM==1, s2_features].stack().replace({-4:9}).unstack()\n",
    "# then copy from first visit\n",
    "X_UDS.loc[:, s2_features] = X_UDS.loc[:, s2_features].replace(-4, np.nan) # no first visit = -4\n",
    "X_UDS.loc[:, s2_features] = X_UDS.loc[:, s2_features].fillna(method='ffill')\n",
    "\n",
    "\n",
    "# drugs\n",
    "# reshape druglist to drug columns with 0 and 1 instead\n",
    "drug_list = df.loc[:, ['DRUG' in j for j in df.columns]].values\n",
    "drug_list = [pd.DataFrame(np.sort(list(set([i for i in j if str(i)!='nan'])))) for j in drug_list]\n",
    "for i in drug_list: i.index = i[0].values\n",
    "\n",
    "drug_df = pd.concat(drug_list, axis=1, sort=False)\n",
    "drug_df = drug_df.transpose()\n",
    "drug_df.index = df.index\n",
    "drug_df = drug_df.fillna(0)\n",
    "# convert any text to number 1\n",
    "drug_df = drug_df.apply(pd.to_numeric, errors='coerce')\n",
    "drug_df = drug_df.fillna(1)\n",
    "drug_df = drug_df.loc[:, drug_df.sum()>0.01*df.shape[0]] #get drugs with at least ~256 occurences\n",
    "\n",
    "# there's some NA's left (all categorical)\n",
    "na_feat = [X_UDS[col].isna().any() for col in X_UDS.columns]\n",
    "X_UDS.loc[:, na_feat] = X_UDS.loc[:, na_feat].fillna(X_UDS.loc[:, na_feat].mode().iloc[0])\n",
    "\n",
    "# merge\n",
    "X_UDS = pd.concat([X_UDS, drug_df], axis=1) \n",
    "\n",
    "# those special cases\n",
    "special_feat = guidelines.loc[guidelines.cleared == 's', 'feature'].values.tolist()\n",
    "special_feat1 = [i for i in special_feat if i not in ['TRAILA', 'TRAILB', 'WAIS', 'NACCAGE']]\n",
    "special_feat2 = ['WAIS']\n",
    "special_feat3 = [i for i in special_feat if i not in special_feat1+special_feat2]\n",
    "\n",
    "## lump all unknown and use mean of that age and cognitive status for impute\n",
    "X_UDS_caseII = X_UDS.copy()\n",
    "X_UDS_caseII.loc[:, special_feat1] = X_UDS_caseII.loc[:, special_feat1].replace({i:np.nan for i in [-4, 88, 95, 96, 97, 98, 99, 995, 996, 997, 998]})\n",
    "X_UDS_caseII.loc[:, special_feat2] = X_UDS_caseII.loc[:, special_feat2].replace({i:np.nan for i in [-4, 95, 96, 97, 98, 99, 995, 996, 997, 998]})\n",
    "X_UDS_caseII.loc[:, special_feat3] = X_UDS_caseII.loc[:, special_feat3].replace({i:np.nan for i in [-4, 995, 996, 997, 998]})\n",
    "imp = KNNImputer(n_neighbors=5)\n",
    "impute_df = pd.concat([X_UDS_caseII.loc[:, special_feat], \\\n",
    "             X_UDS_caseII.NACCAGE, X_UDS_caseII.NACCUDSD, X_UDS_caseII.EDUC], axis=1)\n",
    "imputed_df = pd.DataFrame(imp.fit_transform(impute_df), columns=impute_df.columns, index=impute_df.index)\n",
    "X_UDS_caseII.loc[:, special_feat] = imputed_df.loc[:, special_feat]\n",
    "\n",
    "# # Impute other scores\n",
    "other_scores = [i for i in guidelines.loc[(guidelines.cleared=='y') & (guidelines.categ=='n'), 'feature'].values \n",
    "                if i not in ['NACCID', 'NACCDAGE', 'NACCAGE', 'NACCAGEB', 'NACCUDSD', 'NACCINT']]\n",
    "X_UDS_caseII.loc[:, 'EDUC'] = X_UDS_caseII.loc[:, 'EDUC'].replace({99:np.nan}).fillna(X_UDS_caseII.loc[:, 'EDUC'].median()) #99 for EDUC\n",
    "excluded_columns = np.array(other_scores)[np.where(((X_UDS_caseII.loc[:, other_scores]==-4).sum() > 0).tolist())].tolist()\n",
    "X_UDS_caseII = X_UDS_caseII.loc[:, ~X_UDS_caseII.columns.isin(excluded_columns)]\n",
    "\n",
    "# Cases processed\n",
    "processed_features =  combine_features + dup_features + impCon_features + impCateg_features + id_features + ic_features + \\\n",
    "                     icd_noncateg + r_features + r2_features + ir_features + s2_features + special_feat + other_scores +\\\n",
    "                    ['SMOKYRS', 'PRIMLANG', 'DECAGE', 'TOBAC30', 'TOBAC100'] #+ #drop_features\n",
    "to_be_processed = [i for i in guidelines.feature[guidelines.cleared!='y'] if i not in processed_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_UDS_caseII.to_csv('../project_CR/data/X_UDS_caseII_allFeatures.csv')\n",
    "# y_UDS.to_csv('../project_CR/data/y_UDS_allFeatures.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
